\subsection{Methods}
\label{sec:methods}

In this section, we will introduce the primary ideas we apply to
obtain a level generation pipeline. Before we list the methods, we
take a look at how to actually achieve our task. In the final
subsection, we will talk about Julia, the language the system is
programmed in.

By analyzing inputs of large dimensionality (the level's layers and
metadata), we want to generate similar, new levels of large
dimensionality (also level layers and metadata). This is a very
complex problem, requiring careful planning and a lot of computational
power to train a model large or refined enough to capture all the
essences we need for a new, enjoyable level. A \emph{generative adversarial
network}~(GAN)~\cite{goodfellowGenerativeAdversarialNetworks2014}
would~-- with the present knowledge in machine learning~-- be
exceptionally hard to train on a task with a dimensionality this
large. A lack of proper computational resources makes this even harder
as training a GAN requires training two full models in parallel. While
a GAN would be perfect in theory, allowing us to learn the dataset
without a modified loss function, due to the issues with training, we
try another approach: Generating only the first screen by the GAN and
generating the rest of the level using sequence prediction methods
makes training much easier, allowing us to get a simpler solution to
our problem. Although the results will not be as good as with a GAN
due to a non-adversarial loss function, with some tuning, good results
should be achievable. Also, training of both, the GAN and the sequence
prediction model, should be much easier than a single, large GAN. To
generate the metadata, we use a simple image processing model that
predicts a level's metadata based on its first screen.

The methods will not be listed in pipeline-sequential ordering (the
order in which they will be applied to obtain a generated level) but
instead we will focus on the amount of data the different methods
generate. The sequence prediction task is the most important part of
the pipeline, generating a complete level from a minimal amount of
input. To obtain the first input of the to be predicted sequence, we
use a generative model. Finally, to generate the metadata described on
page~\pageref{par:metadata}, we use an image processor that predicts
the metadata of a level by analyzing its first screen~-- the output of
the generative model and input to the sequence predictor.

Figure~\ref{fig:pipeline} gives a visual summary of the pipeline.

\begin{figure}[t]
  \centering
  % \def\svgwidth{\columnwidth}
  \input{img/pipeline.pdf_tex}
  \caption{An overview of the generation pipeline. Blue blocks
    indicate abstract objects while red block denote models. Not shown
    is the bit indicating whether the level has not ended. The
    metadata vector is concatenated to the first screen as is even
    though the figure may suggest some kind of shortening.}
  \label{fig:pipeline}
\end{figure}

\subsubsection{Sequence Prediction}
\label{sec:sequence-prediction}

The function describing our sequence prediction task in the
3-dimensional case for per-column prediction is
\begin{equation*}
  f: \mathbb{R}^{(k + 1 + r \cdot l) \times c} \to \mathbb{R}^{(1 + r \cdot l) \times c},\ c \in \mathbb{N}^{+},
\end{equation*}
where $k$ is the size of a constant input of metadata (explained in
section~\ref{sec:generation-via-prediction}), $r$ is the amount of
rows in the given level, $l$ is the amount of layers in the given
level and $c$ is the amount of columns in the input (this is
variable). The added~1 in the first matrix dimensionality is a bit
determining whether that column is \emph{not} the last column of the
level. To simplify the above, the input is the level, where each
column is concatenated with a constant vector of metadata and a~1
except for the last column which has a~0 at that place. The output
should be the input (except the constant part of each column) from the
second column onwards with a vector of zeros at the end if the level
has ended or the predicted next column of the level otherwise.
Simplifying even further, given an incomplete level as input, we wish
to predict the next column for each column in the input.

Tasked with completing an unfinished sequence, we turn our head to
sequence prediction models. The models we are using are also called
sequence-to-sequence models. We will closely orient ourselves on
natural language processing techniques, specifically natural language
generation. The models we evaluate are \emph{long short-term memory}
(LSTM)~\cite{hochreiterLongShorttermMemory1997} stacks (with a fully
connected layer at the end) and \emph{transformer}-based
models~\cite{vaswaniAttentionAllYou2017}. More specifically, the LSTM
stacks are based on \emph{char-rnns}~\cite{andrejKarpathyCharrnn2019}
and the transformer-based models are
\mbox{\emph{GPT-2}}~\cite{radfordLanguageModelsAre,OpenaiGpt22019}
models. As a baseline, we implement a non-learning random model that
simply outputs sequences of either~1 or~0 based on a user-supplied
chance $p \in [0, 1]$.

The reason we use techniques from natural language processing is that
levels share many similarities with natural language: References to
both prior and future objects, long-term dependencies and some amount
of redundant information.

A long short-term memory cell's specialty is a recurrent memory that
``remembers'' values of a sequence, depending on connection weights.
Due to this behavior, it is well suited for both non-linear and
long-term dependencies in Mario levels as both can be captured from
any prior, relevant sequence element (for example, a keyhole at the
beginning of the level implies a key later and the other way around).

Transformer-based architectures rely on a combination of attention
functions with multiple ``heads'' and dense networks. These networks
improve upon the LSTM with parallelizability which~-- with the required
computational power for increasingly large neural networks~-- is a very
important factor. Unlike LSTMs, transformers do not keep a hidden
state; they analyze the whole input at once, masking future sequence
elements appropriately if desired (as we do). Due to not having to
keep a state, transformers can analyze multiple different inputs at
once, non-sequentially. This enables the parallelizability which in
turn enables faster training enabling larger models. With these
advantages, we assume that transformers should be better suited to the
task due to its high dimensionality. With the \mbox{GPT-2}
architecture~\cite{radfordLanguageModelsAre}, transformers'
capabilities in natural language generation tasks have been shown.
While those models used an amount of parameters that could not
possibly be trained with our available resources, we hope that a
smaller, with our resources trainable model may still be marginally
larger than an LSTM with the same training time.

\subsubsection{Generative Methods}

The underlying problem in the 3-dimensional domain we are trying to
solve with our generative models is the following:
\begin{equation*}
  g: \mathbb{R}^{n} \to \mathbb{R}^{27 \times 16 \times l},
\end{equation*}
where $n$ is the size of a latent vector of noise our model expects
and $l$ is the amount of layers the generated level will contain.

For our only actual generator in our pipeline, we supply three models:
a standard \emph{deep convolutional generative adversarial network}
(DCGAN)~\cite{radfordUnsupervisedRepresentationLearning2016} and two
\emph{Wasserstein
  GANs}~\cite{arjovskyWassersteinGAN2017,martinarjovskyMartinarjovskyWassersteinGAN2019};
one also based on the DCGAN, another based on fully connected layers
(we will also call these models
MLP-based~\cite{MultilayerPerceptron2019}). Both of these models are
specially fitted with stride, padding and dilation values to obtain
the correct screen size ($27 \times 16 \times l$, where $l$ is the number of
channels or layers).

We decided on using GANs as our generative models due to prior
experience and as we imagined their generative capabilities to be
above
autoencoders~\cite{kramerNonlinearPrincipalComponent1991,kingmaAutoEncodingVariationalBayes2014,Autoencoder2019}.
Whether this is true should be investigated, for example by adding and
testing autoencoder models as well which was sadly not feasible for us
due to time constraints. \\
Another factor in our decision was the hope that the adversarial
objective GANs rely on will improve both the quality and the size of
the space of generated levels as our models will be less prone to
generalization and not have the issues associated with
likelihood-based methods that most autoencoders share as well (unlike
adversarial autoencoders~\cite{makhzaniAdversarialAutoencoders2016}
which solve these, making them a great fit for future experiments). \\
Finally, the reason we employ both convolutional and MLP-based GANs is
primarily due to empirical reasons. While convolutions may suit the
edges in Super Mario World levels, maybe enough levels employ either
too small or not enough edges to make the convolutions worthwhile.

\subsubsection{Image Processing}
\label{sec:image-processing}

Our image processing models, or metadata predictors, learn the
following function in the 3-dimensional case:
\begin{equation*}
  m: \mathbb{R}^{27 \times 16 \times l} \to \mathbb{R}^{k + 1},
\end{equation*}
where $k$ is the size of the constant input (briefly introduced in the
section on sequence prediction models on
page~\pageref{sec:sequence-prediction} and further explained in
section~\ref{sec:preprocessing}) and $l$ is the amount of layers. The
additional dimension is the bit determining whether the level does not
end here (also described in the sections we just mentioned).

Similar to the generative models, we also use both a deep
convolutional network with stride, padding and dilation values fitted
towards the correct screen size and a model consisting of fully
connected layers. Our reasoning for implementing both models was the
same as for the GANs, described above.

Our GAN does not generate the level's metadata in addition to its
first screen (which we assume would be more correct due to
correlations in the network). Even though implementing a generative
model for both first screen and metadata generation would have been
the best solution, we decided to go the direction of simplicity and
decorrelate these two tasks just like we did with the sequence
prediction models. This has a couple of reasons: For one, the added
metadata vector would complicate purely convolutional GANs. Another
reason is that this greatly expands the space of input data from data
in the set~0 to~1 (or interval from~0 to~1 inclusively, depending on
if we normalize the data) to real numbers in the interval from~0
to~512 inclusively (assuming our currently supplied metadata; more
information in section~\ref{sec:preprocessing}). \\
While we are certain that this influences our generative results
negatively, we hope that decoupling these two tasks yields us an
easier time during training. As GAN training is already notoriously
hard, we estimated that opting for a GAN that implements both tasks
would make training even harder. This estimate may be wrong as the
metadata could also help as more correlation in the data may be found.

In the end, while both approaches should be experimented with, this
exercise will be left to subsequent work. The image processing model
may be removed in favor of a GAN-only approach if that proves to be
the better choice.

\subsubsection{Julia}
\label{sec:julia}

Our source code is written in
\emph{Julia}~\cite{bezansonJuliaFreshApproach2017}. Julia is a
programming language whose version~1.0 was released in August~2018. It
presents itself as combining the performance of C, the productivity of
Python and the generality of Lisp. With this combination, we were able
to quickly assemble a very performant, high-level data processing and
low-level machine learning pipeline. It enabled us to~-- for example~--
change our array types as desired, enabling incremental optimization
from standard arrays to GPU arrays to sparse arrays to sparse GPU
arrays. While starting with version~1.1.0, we updated our code to now
work with versions~1.2.0 (the latest stable release)
and~\mbox{1.3.0-rc5} (the latest release candidate for the upcoming
version). Running on a 1.3-version or above enables multi-threading
for the data iterator which may improve training speed by a large
magnitude. Our recommended version to run the code is
therefore~\mbox{1.3.0-rc5} (once 1.3.0~is released as stable, that
should be used instead as we expect no syntax or functionality
changes).

Thanks to community packages, we were able to easily implement
functions accelerated by CUDA~\cite{CUDAToolkit2013} and
cuDNN~\cite{NVIDIACuDNN2014}. \\
While Julia brought great advantages with it, some disadvantages were
issues and bugs in packages and the general immaturity of the
ecosystem (an example concerning array primitives for sparse arrays on
the GPU is given in section~\ref{sec:packages}). Another issue were
long compilation times which are to be addressed soon. \\
We list the most important packages for our pipeline with
explanations, advantages and disadvantages in
section~\ref{sec:packages}.

Next, let us take the theoretical knowledge we introduced in this
section and make it practical in the next one.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../SMWLevelGenerator"
%%% End:

