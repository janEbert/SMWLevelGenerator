\section{Discussion}

The experiments once again show how well neural networks generalize.
In our case, this generalization was a bit too much and we should look
for ways to further de-regularize.

Due to most of the work relying on the sequence prediction models,
these are the weakest link of our pipeline. What we found out is that
the models were not able to memorize the data (overfit on it) but
instead minimized error by heavily generalizing. While we tried giving
the models more layers, this resulted in much higher, oscillating loss
that ultimately was not decreasing even after many epochs.

\subsection{Related Work}

Most related work worked with the simpler environment given by Super
Mario Bros.~\cite{SuperMarioBros2019}. With fewer layers, interactions
and general size, this is~-- while still fundamentally hard~-- a much
simpler problem in relation to the high dimensions we are faced with
in Super Mario World. Also, we deliberately chose to include
non-functional level parts (non-interactive, cosmetic tiles) in our
dataset in the hopes of making generations more like manually created
levels. This should have been a later feature instead when a pipeline
generating better levels was found; none of the related work included
non-functional parts.

We also noticed that a lot of the papers we list here use datasets
much smaller than ours (often even using subsets of the 32~levels in
Super Mario Bros.), most likely for simplification purposes but
possibly also to increase the odds of overfitting which we assume may
be desired. Another possibility may be disregard for or unawareness of
community-created levels. With the training loop parameter
\texttt{overfit\_on\_batch}, originally designed for debugging
purposes, we can emulate this behavior. However, we chose not to go
this way as we wanted to create diversity. In hindsight, this was
probably a bad idea.

A related paper using a column-per-column encoding by Dahlskog et
al.~\cite{dahlskogLinearLevelsNgrams2014} uses
$n$-grams~\cite{Ngram2019} to predict levels based on the same
``style'' found in the training dataset, citing the simplicity of
$n$-grams in modeling surface-level statistics. While capturing the
structure of the training levels well, these models would fail to work
with or ``invent'' never-before seen columns. We hoped to enable this
kind of ``creative generalization'' with our deep learning models.
\medskip

Geitgey~\cite{geitgeyMachineLearningFun2018} successfully predicts
Super Mario Bros.\ levels by using a char-rnn. His approach encoded
the level as a string (with one-hot class encodings, predicting the
next tile), reading it out column per column from top to bottom (like
we do when reading per tile in default order); his model was also
responsible for setting the length of the columns, making his problem
space significantly larger. Due to the combinatorial explosion of
classes when predicting per column\footnote{With
  $d = 2^{l \cdot r} \cdot 512 \cdot 32 \cdot 7 \cdot 14 \cdot 8 \cdot 8 \cdot 2 \cdot 2 \cdot 18$, where
  fixed numbers are the amount of possible values of the constant
  metadata vector, $l$~is the number of layers, $r$~the number of rows
  and $d$ the resulting number of classes, for 3-dimensional input
  columns containing all layers ($l = 2164$, $r = 27$), $d$ has
  17\,599~\emph{digits} compared to $d = 662$ for $r = 1$ (per-tile
  input).} and for efficiency reasons, we had foregone the approach of
class encoding initially. However, with the already implemented option
of reading per tile and the new-found knowledge of our experiments, we
should revisit and implement this approach for future experiments.

Summerville and Mateas~\cite{summervilleSuperMarioString2016} analyze
several methods of encoding the level, ultimately also deciding that
per-tile encodings are easier to learn than per-column encodings. They
also propose using ``snaking'', alternating reading each column from
bottom to top, then from top to bottom. This benefits locality in the
sequence and artificially doubles the dataset enabled by starting the
snaking from either bottom to top or top to bottom. Another
proposition is adding another value to the input~-- a continually
increasing value to enable a better understanding of level progression
to the model. They also use A* search~\cite{SearchAlgorithm2019}
to enable better playability of the level. \\
This was not relevant to our case for two reasons: (1)~contrary to
Super Mario Bros., Super Mario Word allows backtracking, making it
impossible to only consider linear paths and (2)~due to the largely
increased amount of interactions, we cannot assume that tracking a
path over tiles leads to the completion of a level. However, the path
enabled controlling the difficulty of the level by widening or
shrinking the possible paths and lead to better results; pursuing an
approach similar to path search may be worthwhile.
\medskip

Volz et
al.~\cite{volzEvolvingMarioLevels2018,thehedgeifyTheHedgeifyDagstuhlGAN2019}
used a Wasserstein DCGAN with gradient penalty together with the
covariance matrix adaptation evolution
strategy~(CMA-ES)~\cite{hansenCompletelyDerandomizedSelfAdaptation2006}
to do an evolutionary search over the latent space of the GAN's inputs
after training. With this, they can control certain features such as
the number of ground tiles and enemies. This in turn enables
controlling the difficulty of a generated level by~-- for example~--
generating less ground and more enemies to increase the difficulty;
this is even applicable gradually. They also used agent-based testing
to ensure playability of the levels. Finally, even though their
dataset consisted of a single level, the results show more variability
than expected. This variability was a byproduct of using an actual
generative approach, making moving through the latent space for
individual chunks of the level possible to obtain gradual mutations.

Giacomello et al.\ successfully used both a unconditional and
conditional Wasserstein GAN with gradient
penalty~\cite{gulrajaniImprovedTrainingWasserstein2017} to generate
DOOM~\cite{Doom1993Video2019} levels. Both GANs take as input image
representations of the level (representing platforms, walls, \dots)
while the conditional version additionally receives other important
information about the level such as metadata (title, author, number of
downloads, \dots) or heavily engineered features (size, number of
rooms, equivalent diameter of the level volume, \dots). While DOOM is
a 3-dimensional first-person shooter, the authors in turn base their
work on papers related to platform level generation for Super Mario
Bros., completing the cycle. The authors show that a GAN-only approach
works well in a complex domain; considering conditional information
(by this we mean both GANs receiving prior level information; this is
not unique to the conditional GAN) was not in our interest but may be
desired to improve results.

\subsection{Future Improvements}

While the experiments have shown that our approach to generating
levels via sequence prediction have not worked out yet, we have many
suggestions and possible solutions that ought to be tried out in the
future in addition to the ones already mentioned in the previous
section. We also have several improvements planned for the project
which are out of the scope of this thesis. However, we do want to
mention that a distributed version would make a lot of sense for
larger models; then, training models for the 3-dimensional case with
all layers may be feasible.

As is usual in deep learning, for all our models, tuning the
hyperparameters further may lead to surprising results. While we do
not believe~-- looking at the experiments and our prior discussion
above~-- that only changing hyperparameters will lead to a good level
generator, with deep learning you never know if the combined changes
over many parameters may suddenly lead to a good result. In
particular, reducing or removing dropout may help. \\
We also believe the training pipeline in general would benefit from
further features such as learning rate regulation (especially for
warm-up).

While a lack of features may be influencing our results, a lot of
features we implemented could sadly not be tested well due to time
constraints. These include the per-tile encoding, ``soft'' loss and
the LSTMs' skip connections.

In terms of the sequence prediction models, first off, we should try
training on generated data that goes back some amount steps into the
past instead of only on ``perfectly'' predicted data~-- the actual,
ground truth data (we mentioned this in
section~\ref{sec:generation-via-prediction}). This would allow
minimizing errors for future predictions. As we see, we cannot rely on
the model to predict the next column perfectly, meaning an error for
each predicted column will accumulate and result in worse and worse
predictions.

We could try implementing more loss functions akin to the ``soft''
loss we introduced in section~\ref{sec:generation-via-prediction} as
well. Another promising improvement would be implementing adversarial
sequence
generators~\cite{yuSeqGANSequenceGenerative2017,liAdversarialDiscreteSequence}
which we had initially foregone due to considerations regarding the
high dimensionality of our data. With those, the GANs and~-- possibly~--
the metadata predictor become redundant, leading us to a single model
capable of generating complete levels from scratch.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../SMWLevelGenerator"
%%% End:

